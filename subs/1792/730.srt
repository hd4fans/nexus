1
00:00:15,230 --> 00:00:25,230
字幕校对+特效: 月亮花@MySiLU思路高清

2
00:00:46,230 --> 00:00:51,890
片名：机械公敌

3
00:01:00,230 --> 00:01:05,890
定律一： 机器人不能伤害人类或使人类间接受到伤害

4
00:01:13,000 --> 00:01:19,660
定律二： 机器人必须服从人类的命令 除非该命令与定律一冲突

5
00:01:30,060 --> 00:01:38,720
定律三： 机器人必须保护自己的存在 除非与第一或第二定律冲突

6
00:03:12,230 --> 00:03:13,890
多漂亮啊
Thing of beauty.

7
00:03:19,440 --> 00:03:21,240
早上好，先生！
Good morning, sir!

8
00:03:21,410 --> 00:03:24,240
您的订单已经及时送到。。。
Yet another on-time delivery from--

9
00:03:24,410 --> 00:03:26,900
让开，铁皮人
Get the hell out of my face, canner.

10
00:03:27,280 --> 00:03:29,250
祝您今天愉快！
Have a nice day!

11
00:03:29,230 --> 00:03:33,890
芝加哥，2035年

12
00:03:31,680 --> 00:03:36,180
我们相信我们的“梦想目的” 套票是您最好的选择
And we believe our Destination Anywhere package to be the best value.

13
00:03:36,390 --> 00:03:41,590
星际旅行机X－82，能把您送到梦想中的目的地
Let us take you to your dream destination aboard our orbital spaceplane, the x-82.

14
00:03:46,160 --> 00:03:51,600
试试爵士城的合成芝加哥口味比萨饼 就像您记忆中的味道一样
Try Jazztown 's synthetic Chicago-style pizza. Tastes as good as you remember.

15
00:03:52,700 --> 00:03:55,940
荧光鱼！世界最热卖的转基因礼物
Glowfish! The world's hottest-selling transgenic treats.

16
00:03:56,110 --> 00:03:59,670
你的孩子也会喜欢新的颜色的！
Your children will love the new colors too!

17
00:04:00,980 --> 00:04:02,880
-对不起，先生 -最强性能
-Excuse me, sir. -Total performance.

18
00:04:03,050 --> 00:04:05,540
完全准备就绪，绝对安全
Total readiness. Total security.

19
00:04:05,720 --> 00:04:08,020
向无休止的升级和服务电话说再见吧
So goodbye to upgrades and service calls.

20
00:04:08,190 --> 00:04:10,280
和USR中央电脑连线
An uplink to USR's central computer...

21
00:04:10,460 --> 00:04:13,890
提供每天实时更新超级机器人服务
...provides this state-of-the-art robot with new programs daily.

22
00:04:14,060 --> 00:04:17,290
内斯特5型机器人，明日技术，今日奉献
The Nestor Class 5 is tomorrow 's robot today.

23
00:04:18,060 --> 00:04:20,500
斯普恩！斯普那！
Spoon! Spoonie!

24
00:04:24,440 --> 00:04:27,960
等等，等等！ 对不起
Hold up. Hold on! Excuse me, excuse me.

25
00:04:28,140 --> 00:04:30,630
-斯普那，你最近去哪儿了？ -离开了一阵子，法伯
-Spoon, where you been at? -Just away, Farber.

26
00:04:30,810 --> 00:04:33,680
是吗，离开，度假吗？真不错啊！
Oh, yeah, away? Like vacation? That's nice.

27
00:04:33,880 --> 00:04:37,250
我要你帮个忙。。。 我要借你的车
I got a favor to ask. I need to borrow your car.

28
00:04:37,520 --> 00:04:42,080
这次不同了，我弄上了这个 热辣的小妞
This is different. I got this fine-ass yummy-- She is complete and agreeable.

29
00:04:42,390 --> 00:04:44,050
绝对不错
I mean, ass-hot spankable.

30
00:04:44,260 --> 00:04:46,920
-你说什么意思呢？ -你知道我什么意思的
-What does that even mean? -You know what it means.

31
00:04:47,090 --> 00:04:49,530
-让我借你的钥匙一用。。。 -首先来说。。。
-Let me get the damn-ass keys. -First of all...

32
00:04:49,700 --> 00:04:53,860
不要说脏话了，你说的完全不对 -那给我十块钱坐公车行吗
-...stop cussing. You're not good at it. -Give me 1 0 for the bus, then, man.

33
00:04:54,200 --> 00:04:57,760
-回家去吧 -好吧，算了
-Go home. -That's strike one, Spoon. Strike one!

34
00:05:14,720 --> 00:05:17,880
多么美好的一天。。。
This is such a valuable day....

35
00:05:18,190 --> 00:05:20,280
你和马茜谈过了吗？
You talk to Marci?

36
00:05:22,360 --> 00:05:24,590
还没，琪琪，我还没和马茜谈过
No, Gigi, I haven't talked to Marci.

37
00:05:24,760 --> 00:05:28,060
我们那个时代，我们可不会 和某人结婚
When I was coming up, we didn't just marry someone...

38
00:05:28,230 --> 00:05:31,030
离婚之后就不和他说话了
...then divorce them, then not talk to them.

39
00:05:31,200 --> 00:05:32,930
德尔，不要耍花样
Del, don't play with me.

40
00:05:33,110 --> 00:05:37,570
我打赌如果我不做饭了 你就会打电话给马茜
I bet if I stopped cooking, you'd call Marci.

41
00:05:38,640 --> 00:05:41,640
啊，你脚上穿的那是什么？
Boy, what is that on your feet?

42
00:05:42,550 --> 00:05:45,520
康佛斯全明星鞋，2004年行货
Converse All Stars, vintage 2004.

43
00:05:46,750 --> 00:05:49,920
不要做那种表情 我知道你想要，开口就行了
Don't turn your face up. I know you want some. Just ask.

44
00:05:50,090 --> 00:05:52,610
不，谢谢你了
No, thank you very much.

45
00:05:52,920 --> 00:05:55,790
-甜土豆饼啊 -放在盘子上吃
-Sweet potato pie. -Put that on a plate.

46
00:05:56,630 --> 00:06:01,430
电视里说他们在抽奖赠送新型的机器人
I've seen on TV they're giving away some of them new robots in the lottery.

47
00:06:01,830 --> 00:06:06,130
你知道，琪琪，那些机器人干不了什么好事
You know, Gigi, those robots don't do anybody any good.

48
00:06:06,300 --> 00:06:09,470
在这世界上，你应该比谁都清楚
Of all the people on God's earth, you should know better.

49
00:06:09,640 --> 00:06:13,410
有时候你说话完全不经过大脑
Sometimes the stuff that comes out of your mouth!

50
00:06:14,850 --> 00:06:16,970
你在听我说吗？德尔？
You listening to me, Del?

51
00:06:28,460 --> 00:06:29,690
嘿！
Hey!

52
00:06:29,930 --> 00:06:31,260
嘿！
Hey!

53
00:06:35,130 --> 00:06:37,500
拿着我的饼，先生，不然我就扔到你身上了
Hold my pie. Sir, hold it or wear it.

54
00:06:44,340 --> 00:06:45,470
让开！
Move!

55
00:06:53,080 --> 00:06:54,640
不许动！
Freeze!

56
00:06:58,720 --> 00:07:00,280
嘿！停下！
Hey! Stop!

57
00:07:09,630 --> 00:07:11,100
停下！
Stop!

58
00:07:16,740 --> 00:07:18,170
我说了，停下！
I said, stop!

59
00:07:20,710 --> 00:07:22,650
放松，放松
Relax. Relax.

60
00:07:22,810 --> 00:07:24,650
我是警官
I'm a police officer.

61
00:07:24,820 --> 00:07:26,010
你
You...

62
00:07:26,920 --> 00:07:29,220
是个蠢货
...are an asshole.

63
00:07:29,390 --> 00:07:32,850
-女士，这是你的钱包吗？ -当然是我的钱包
-Ma'am, is that your purse? -Of course it's my purse.

64
00:07:33,020 --> 00:07:36,520
我把呼吸器忘在家里了 他跑去给我拿来的
I left my inhaler at home. He was running it out to me.

65
00:07:36,700 --> 00:07:39,360
我看见一个机器人拿着钱包在跑 我以为。。。
I saw a robot running with the purse and assumed--

66
00:07:39,760 --> 00:07:41,820
以为什么？你疯了吗？
What? Are you crazy?

67
00:07:42,570 --> 00:07:45,560
-对不起，让您误解了 -不要道歉
-I'm sorry for this misunderstanding. -Don't apologize.

68
00:07:45,740 --> 00:07:49,500
你在干你该干的事 你呢？你在干什么？
You're doing what you're supposed to do. But what are you doing?

69
00:07:50,740 --> 00:07:52,110
祝您今天愉快，女士
Have a lovely day, ma'am.

70
00:07:52,280 --> 00:07:56,770
算你运气好，我现在呼吸困难 不然你吃不了兜着走
You're lucky I can't breathe, or I'd walk all up and down your ass.

71
00:08:19,300 --> 00:08:22,100
以事实为依据
Lead by example.

72
00:08:23,480 --> 00:08:25,670
你的警徽上是这么说的
It says that right on your badge.

73
00:08:25,880 --> 00:08:27,940
-我们谈谈这件事？ -什么事？
-We gonna talk about this? -About what?

74
00:08:28,110 --> 00:08:32,240
警察救命啊，那个机器人偷了 我的干洗衣服！
"Help! Police! That robot stole my dry cleaning!"

75
00:08:33,050 --> 00:08:35,040
哦，你想谈谈那个
Oh, you wanna talk about that.

76
00:08:36,720 --> 00:08:38,450
探员。。。
Detective...

77
00:08:39,190 --> 00:08:43,420
-有多少机器人偷过钱包？ -约翰，那家伙在跑。。。
-...how many robots snatch purses? -John, the thing is running--

78
00:08:43,600 --> 00:08:47,120
世界上有多少机器人。。。
How many robots in the world...

79
00:08:47,300 --> 00:08:50,100
犯过罪？ -给犯罪下个定义
-...have ever committed a crime? -Define crime.

80
00:08:50,300 --> 00:08:53,000
-回答我的问题 -没有，约翰
-Answer my question, damn it. -None, John.

81
00:08:55,640 --> 00:08:58,510
现在告诉我，今天发生了什么事
Now tell me what happened today.

82
00:08:59,640 --> 00:09:01,310
没什么事
Nothing.

83
00:09:03,110 --> 00:09:04,910
最好这是最后一次了
Better be the last nothing.

84
00:09:10,820 --> 00:09:15,780
斯普恩，你确定你已经准备好回来了吗？ 你可以慢慢来的，不急
Spoon, are you sure you are ready to be back? Because you can take your time.

85
00:09:15,960 --> 00:09:19,260
我没事，约翰，谢谢你
I'm fine, John. Thank you.

86
00:09:19,800 --> 00:09:23,360
总比坐在家里好
Better here than sitting around at home.

87
00:09:29,270 --> 00:09:31,470
重案组，斯普那
Homicide. Spooner.

88
00:09:44,890 --> 00:09:47,260
请从右边下一个出口离开
Please take the next exit to your right.

89
00:10:00,340 --> 00:10:02,530
欢迎，斯普那探员
Welcome, Detective Spooner.

90
00:10:07,580 --> 00:10:11,910
欢迎来到美国机器人公司 您已经进入底层大厅
Welcome to U. S. Robotics. You have entered the garage-level lobby.

91
00:10:12,150 --> 00:10:16,750
请坐电梯进入一楼大厅
Please use the elevators for direct access to the main level concourse.

92
00:10:16,920 --> 00:10:18,350
谢谢你
Thank you.

93
00:10:19,320 --> 00:10:22,920
-很高兴再次见到你，年轻人 -你好，博士
-Good to see you again, son. -Hello, doctor.

94
00:10:23,160 --> 00:10:27,000
接下来的一切都是你现在看到的事情的结果
Everything that follows is a result of what you see here.

95
00:10:27,530 --> 00:10:32,830
-你有什么要告诉我的吗？ -对不起，我的回答有限
-ls there something you want to tell me? -I'm sorry. My responses are limited.

96
00:10:33,000 --> 00:10:35,000
你必须问正确的问题
You must ask the right questions.

97
00:10:35,170 --> 00:10:37,110
你为什么找我？
Why did you call me?

98
00:10:37,910 --> 00:10:39,880
我相信你的判断
I trust your judgment.

99
00:10:40,050 --> 00:10:43,240
一般来说，这应该用不着重案组的探员
Normally, this wouldn't require a homicide detective.

100
00:10:43,420 --> 00:10:47,610
但是一直以来，我们的交流就不是 完全正常，不是吗？
But then, our interactions have never been entirely normal, agreed?

101
00:10:47,820 --> 00:10:49,950
你说的对
You got that right.

102
00:10:50,620 --> 00:10:53,110
你有什么要告诉我的吗？
Is there something you want to say to me?

103
00:10:53,320 --> 00:10:57,020
对不起，我的回答有限
I'm sorry. My responses are limited.

104
00:10:57,200 --> 00:10:59,760
你必须问正确的问题
You must ask the right questions.

105
00:11:00,470 --> 00:11:02,260
你为什么自杀？
Why would you kill yourself?

106
00:11:02,700 --> 00:11:06,190
这个，探员，就是正确的问题
That, detective, is the right question.

107
00:11:09,370 --> 00:11:11,540
程序中止
Program terminated.

108
00:11:30,500 --> 00:11:32,590
再见了，老人
Goodbye, old man.

109
00:11:47,510 --> 00:11:49,810
-下午好啊，兄弟们 -你好，探员
-Afternoon, boys. -Hey, detective.

110
00:11:50,010 --> 00:11:52,450
-说说看 -所见即所得
-Enlighten me. -What you see is what you get:

111
00:11:52,620 --> 00:11:53,850
严重撞击伤
Massive impact trauma.

112
00:11:54,020 --> 00:11:56,750
美国机器人公司 我得给孩子带点什么回去
U.S. Robotics. I gotta get my kid something.

113
00:11:57,160 --> 00:11:59,250
-楼上有什么？ -什么也没有
-Anything upstairs? -Nada.

114
00:11:59,420 --> 00:12:01,650
门从内侧锁的很好
Door was security locked from the inside.

115
00:12:01,830 --> 00:12:06,420
吓，肯定是从上面跳下来的
Wham, splat. The guy's a jumper for sure.

116
00:12:13,040 --> 00:12:17,000
我们得聪明点，晚些时候再谈
We gotta be smart about this. Let's deal with it later.

117
00:12:17,840 --> 00:12:19,670
探员
Detective.

118
00:12:20,110 --> 00:12:21,840
劳伦斯 罗伯森
Lawrence Robertson.

119
00:12:23,480 --> 00:12:26,420
世界上最富有的人 我在电视上看见过你
Richest man in the world. I've seen you on television.

120
00:12:27,220 --> 00:12:30,650
-要喝点咖啡吗？ -当然了，为什么不呢？是免费的吧？
-Can I offer you coffee? -Sure, why not. It's free, right?

121
00:12:35,360 --> 00:12:37,850
大家都没预想到这一点
I don't think anyone saw this coming.

122
00:12:38,030 --> 00:12:41,470
你知道，我应该能预见到的 我认识他二十年了
You know, I should have, I suppose. I knew him 20 years.

123
00:12:41,630 --> 00:12:46,040
阿尔弗雷德发明了实用的机器人 他定义了三大定律
Alfred practically invented robotics. He wrote the Three Laws.

124
00:12:47,540 --> 00:12:52,370
但是我想最聪明的人也有 最顽固的心魔
But I guess brilliant people often have the most persuasive demons.

125
00:12:52,540 --> 00:12:55,570
-如果我能帮上什么忙的话。。。 -糖（甜心）
-So whatever I can do to help-- -Sugar.

126
00:12:55,810 --> 00:12:58,480
-什么？ -咖啡用的
-I'm sorry? -For the coffee.

127
00:12:58,650 --> 00:13:00,210
糖？
Sugar?

128
00:13:00,720 --> 00:13:04,090
哦，你以为我叫你“甜心” 你还没有那么有钱
You thought I was calling you "sugar." You're not that rich.

129
00:13:04,260 --> 00:13:07,250
-桌子上就有 -谢谢你
-It's on the table. -Thank you.

130
00:13:11,500 --> 00:13:14,490
兰尼掉下去的时候，他握着 那个绿色的小东西？
When Lanning fell, he was holding the little green...?

131
00:13:14,670 --> 00:13:16,760
-全息投影器 -对
-The holographic projector. -Right.

132
00:13:17,000 --> 00:13:20,100
你认为为什么兰尼的投影像会 找我？
Why do you think Lanning's hologram would've called me?

133
00:13:20,270 --> 00:13:23,570
-我觉得他认识你 -是啊，我是认识他
-I assumed you knew him. -Yeah. I knew him.

134
00:13:24,840 --> 00:13:27,240
全息图是事先录制的程序反应
Holograms are just prerecorded responses...

135
00:13:27,410 --> 00:13:30,210
看上去似乎有智能的样子
...designed to give the impression of intelligence.

136
00:13:30,380 --> 00:13:33,210
这个是设定好了他自杀的时候 就联系你
This one was programmed to call you upon his suicide.

137
00:13:33,420 --> 00:13:35,850
-死亡 -什么？
-Death. -I'm sorry?

138
00:13:36,020 --> 00:13:39,510
设定的是兰尼死的时候联系我
It was programmed to call me in the event of Lanning's death.

139
00:13:39,790 --> 00:13:42,120
自杀是死亡的一种，探员
Suicide is a type of death, detective.

140
00:13:46,260 --> 00:13:49,720
-请不要以为我不耐烦 -哦，没有，不会
-Don't misunderstand my impatience. -Oh, no. Go. Go.

141
00:13:51,600 --> 00:13:54,870
这个星期你们这里会很忙啊
A really big week for you folks around here.

142
00:13:55,040 --> 00:13:57,410
你要给每个家庭都装一个机器人
You gotta put a robot in every home.

143
00:13:57,810 --> 00:14:02,250
我不是干这个的，不过我有个 关于你们广告的主意
Look, this is not what I do, but I got an idea for one of your commercials.

144
00:14:02,410 --> 00:14:06,140
可以先来个木匠，做了一把 漂亮的椅子
You could see a carpenter making a beautiful chair.

145
00:14:06,320 --> 00:14:10,520
然后又来个你们的机器人 做了一把更好的椅子，只花一半时间
Then one of your robots comes in and makes a better chair twice as fast.

146
00:14:10,960 --> 00:14:15,950
然后字幕打出来： USR，彻底打败他
Then you superimpose on the screen, " USR: Shitting on the little guy."

147
00:14:18,230 --> 00:14:19,720
然后淡出
That would be the fade-out.

148
00:14:19,900 --> 00:14:23,660
我明白了，也许是你爸爸因为 机器人丢了工作
Yeah, I see. I suppose your father lost his job to a robot.

149
00:14:23,970 --> 00:14:27,960
也许你应该呼吁禁止互联网 代之以图书馆
Maybe you'd have banned the lnternet to keep the libraries open.

150
00:14:29,910 --> 00:14:32,310
偏见总是没有太多理由的
Prejudice never shows much reason.

151
00:14:32,480 --> 00:14:36,280
我觉得你就是不喜欢它们这个种群
No, you know, I suspect you simply don't like their kind.

152
00:14:37,050 --> 00:14:40,110
你在这儿有你的生意要做
Well, you got a business to run around here.

153
00:14:40,290 --> 00:14:44,350
尤其是这个星期，你最不希望见到的 就是一个死人躺在你的大厅里
The last thing you need, especially this week, is a dead guy in your lobby.

154
00:14:44,660 --> 00:14:48,150
但是既然已经发生了，我就只好四处调查看看
But, hell, seeing as how you got one, maybe I'll look around.

155
00:14:48,330 --> 00:14:51,560
问几个问题而已 警察的例行公事么
Ask a few questions. Do the whole "cop" thing.

156
00:14:51,960 --> 00:14:55,420
-我会派人指引你的 -非常感谢
-I'll send someone to escort you. -Thank you very much.

157
00:15:07,850 --> 00:15:10,840
劳伦斯要我尽一切可能帮助你
Lawrence told me to accommodate you in any way possible.

158
00:15:11,020 --> 00:15:12,570
是吗？
Really?

159
00:15:13,380 --> 00:15:14,650
好啊
Okay.

160
00:15:15,620 --> 00:15:18,650
我看过兰尼博士的心理学档案了
I reviewed Dr. Lanning's psych profile.

161
00:15:18,890 --> 00:15:23,120
阿尔弗雷德变得很隐遁 拒绝人类和机器的接触
Alfred had become a recluse. He rejected human contact for machines.

162
00:15:23,290 --> 00:15:25,190
你是个心理医生？
So you're a shrink, huh?

163
00:15:25,700 --> 00:15:28,190
我的前妻知道我和你谈话一定很高兴
My ex-wife would sure be glad I'm talking to you.

164
00:15:28,700 --> 00:15:30,360
你不认识她，对吧？
You don't know her, do you?

165
00:15:30,600 --> 00:15:32,360
对不起，你在开玩笑吗？
I'm sorry. Are you being funny?

166
00:15:32,740 --> 00:15:34,570
没有啊
I guess not.

167
00:15:35,040 --> 00:15:37,230
10楼
Level 10.

168
00:15:37,410 --> 00:15:40,670
你认为兰尼博士有自杀倾向？
So would you say that Dr. Lanning was suicidal?

169
00:15:40,880 --> 00:15:43,310
我认为答案是很明显的
It would seem the answer to that is apparent.

170
00:15:43,650 --> 00:15:46,010
这不是我问你的问题
That's not what I asked you.

171
00:15:47,120 --> 00:15:49,180
不，我本来不这么认为
No. I wouldn't have thought so.

172
00:15:49,750 --> 00:15:52,050
但是，很显然我错了
But obviously I was wrong.

173
00:15:55,260 --> 00:15:57,090
这里掉下去可是很高啊
That's a long way down.

174
00:15:57,260 --> 00:15:59,920
你们清扫的还真快
You people sure do clean up quickly around here.

175
00:16:00,260 --> 00:16:03,830
我不怪你，谁愿意让这么个老头子 死在大厅里呢？
I can't blame you. Who wants some old guy going bad in the lobby?

176
00:16:04,000 --> 00:16:08,530
他可不是什么“老头子” 阿尔弗雷德 兰尼是这里的一切
He was not "some old guy." Alfred Lanning was everything here.

177
00:16:09,140 --> 00:16:12,630
我们即将进行史上最大的机器人上市活动
We are on the eve of the largest robotic distribution in history.

178
00:16:12,840 --> 00:16:16,340
在星期六之前，每5个家庭就会拥有一个机器人
By Saturday, it'll be one robot to every five humans.

179
00:16:16,550 --> 00:16:20,540
这些机器人是梦想的实现 兰尼博士的梦想
These robots are the realization of a dream. Dr. Lanning's dream.

180
00:16:21,220 --> 00:16:24,280
你知道吗？在他的梦中
You know what, in that dream of his...

181
00:16:24,460 --> 00:16:26,720
我打赌他没有翘掉
...I bet you he wasn't dead.

182
00:16:29,260 --> 00:16:32,590
-你们这里有全天监视吗？ -当然了，公司的规定
-You keep 24-hour surveillance? -Obviously. Company policy.

183
00:16:32,760 --> 00:16:36,260
-监视器呢？ -感应线
-Where are the feeds? -Sensor strips.

184
00:16:36,430 --> 00:16:38,370
除了检修区之外，遍布各处
Everywhere but the service areas.

185
00:16:38,570 --> 00:16:41,800
这些都连到中央控制器
They link to our positronic operating core.

186
00:16:47,810 --> 00:16:51,300
热感应器还不够好 你们给了这幢大楼一个大脑啊
Thermostat wasn't good enough. You gave the building a brain.

187
00:16:51,480 --> 00:16:53,920
她是兰尼的第一个作品
She was actually Lanning's first creation.

188
00:16:54,090 --> 00:16:57,750
她？是“她”吗？ 那可得讨好她
She? That's a she? I definitely need to get out more.

189
00:16:57,920 --> 00:17:00,550
虚拟交互动力智能系统
Virtual lnteractive Kinetic lntelligence.

190
00:17:01,430 --> 00:17:03,190
维基
V.I.K.I.

191
00:17:03,630 --> 00:17:04,720
您好
Good day.

192
00:17:05,000 --> 00:17:07,330
维基设计了芝加哥的保安系统
V.I.K.I. designed Chicago's protective systems.

193
00:17:07,700 --> 00:17:11,160
我今年减少了9％的交通事故
I have decreased traffic fatalities by 9 percent this year.

194
00:17:11,340 --> 00:17:15,770
谢谢，让我看看窗户打破前一分钟 实验室内的情况
Thanks. Show me inside the lab from one minute prior to the window break.

195
00:17:19,810 --> 00:17:23,210
对不起，数据似乎已经损坏
Apologies. There appears to be data corruption.

196
00:17:24,350 --> 00:17:27,510
让我看看实验室外从破窗到现在的情况
Show me outside the lab from the window break until now.

197
00:17:36,930 --> 00:17:41,630
看看，你站的姿势不错 站的很直，我却缩手缩脚
Look, you have great posture. You stand really straight. I'm slouching.

198
00:17:42,000 --> 00:17:45,770
-你想进去看看吗？ -哦，当然了，你来带路
-Would you like to go inside now? -Oh, sure. Right after you.

199
00:17:47,670 --> 00:17:49,830
授权进入
Authorized entry.

200
00:17:57,350 --> 00:18:01,510
那么，凯文博士，你在这里的工作 是什么？
So, Dr. Calvin, what exactly do you do around here?

201
00:18:01,750 --> 00:18:04,740
一般是高级机器人学和精神科学
My general fields are advanced robotics and psychiatry.

202
00:18:04,960 --> 00:18:07,520
专长是硬件软件接口
I specialize in hardware-to-wetware interfaces...

203
00:18:07,690 --> 00:18:12,290
提升USR机器人的人格化系统
...to advance USR's robotic anthropomorphization program.

204
00:18:12,460 --> 00:18:15,160
哦，那你的工作是什么？
So, what exactly do you do around here?

205
00:18:15,330 --> 00:18:17,770
我让机器人更像人
I make the robots seem more human.

206
00:18:17,970 --> 00:18:22,170
-这样说不是简单多了吗？ -不完全是
-Now, wasn't that easier to say? -Not really. No.

207
00:18:44,160 --> 00:18:45,920
韩瑟和格丽托
"Hansel and Gretel."

208
00:18:46,100 --> 00:18:49,560
-这是USR的必读书目吗？ -不是啊
-ls that on the USR reading list? -Not precisely.

209
00:18:58,740 --> 00:19:01,230
你在干什么？
What in God's name are you doing?

210
00:19:01,610 --> 00:19:03,740
你知道这是安全玻璃吗？
Did you know that was safety glass?

211
00:19:03,920 --> 00:19:07,080
一个老人要撞破玻璃跳下去不容易吧？
Be difficult for an old man to throw himself through that.

212
00:19:07,250 --> 00:19:09,120
他想出办法了
Well, he figured out a way.

213
00:19:12,260 --> 00:19:16,060
探员，这房间一直是锁好的 没有人进出过
Detective, the room was security locked. No one came or went.

214
00:19:16,230 --> 00:19:20,220
你自己也看见了 这还不是自杀吗？
You saw that yourself. Doesn't that mean this has to be suicide?

215
00:19:20,460 --> 00:19:22,060
是啊
Yep.

216
00:19:22,930 --> 00:19:25,630
除非凶手还在这里
Unless the killer's still in here.

217
00:19:28,270 --> 00:19:31,610
你在开玩笑对吧？这真可笑
You're joking, right? This is ridiculous.

218
00:19:31,780 --> 00:19:35,970
我知道，三大定律，完全保护
Yeah, I know. The Three Laws, your perfect circle of protection.

219
00:19:36,480 --> 00:19:40,640
机器人不能危害人类 这是机器人第一定律
A robot cannot harm a human being. The first law of robotics.

220
00:19:40,850 --> 00:19:45,650
我看过你们的广告，但是第二定律不是 说，机器人必须遵守
Yes, I've seen your commercials. But the second law states a robot must obey...

221
00:19:45,920 --> 00:19:49,650
人类发出的命令吗？ 如果命令是让它杀人怎么办？
...any order given by a human being. What if it was told to kill?

222
00:19:49,930 --> 00:19:52,660
不可能的，这和第一定律冲突
Impossible. It would conflict with the first law.

223
00:19:52,860 --> 00:19:55,990
对，但是第三定律说机器人可以自我防卫
Right, but the third law states a robot can defend itself.

224
00:19:56,270 --> 00:20:00,600
只有当这和第一第二定律不冲突的时候
Only when that action does not conflict with the first or second laws.

225
00:20:00,770 --> 00:20:04,000
你知道他们怎么说的吗？ 法律制定出来就是为了被破坏的
You know what they say, laws are made to be broken.

226
00:20:04,180 --> 00:20:07,300
不，这些定律不会 这些都是固化在机器人硬件里的
No, not these laws. They're hardwired into every robot.

227
00:20:07,750 --> 00:20:11,480
机器人不能杀人，就像人不能 在水上行走一样
A robot could no more commit murder than a human could walk on water.

228
00:20:11,650 --> 00:20:15,310
你知道，很久以前就有这么个人。。。
You know, there was this one guy a long time ago.

229
00:20:26,400 --> 00:20:28,660
-退后 -镇定，探员
-Stay back! -Calm down, detective.

230
00:20:29,400 --> 00:20:32,390
这房间里危险的人就只有你
The only thing dangerous in this room is you.

231
00:20:32,600 --> 00:20:35,040
停机
Deactivate.

232
00:20:36,170 --> 00:20:37,610
看，没事了
Look, it's fine.

233
00:20:38,040 --> 00:20:42,810
这是智能程序的反应 是对自由意志的模仿
You're looking at the result of clever programming. An imitation of free will.

234
00:20:42,980 --> 00:20:45,470
让我们先模仿好保护自己吧
Let's do an imitation of protecting our asses.

235
00:20:45,650 --> 00:20:47,780
不要搞笑了
Don't be absurd.

236
00:20:48,190 --> 00:20:50,420
你被“盒子里的小丑”吓住了
You were startled by a jack-in-the-box.

237
00:20:50,990 --> 00:20:52,980
-停机！ -让它来吧
-Deactivate! -Let him go.

238
00:20:53,160 --> 00:20:55,890
他不会伤害我们 我命令你！
It's not going to hurt us. I gave you an order!

239
00:20:56,060 --> 00:20:59,220
-他不听你的，女士 -维基，封锁实验室
-He's not listening right now, lady. -V.I.K.I., seal the lab!

240
00:20:59,430 --> 00:21:00,920
不，维基，不要。。。
No, V.I.K.I., leave the--

241
00:21:02,000 --> 00:21:03,930
命令确认
Command confirmed.

242
00:21:28,190 --> 00:21:29,520
警察！
Police!

243
00:22:02,490 --> 00:22:06,090
-你把它伤的很重 -它去哪儿了？
-You've hurt it. Badly. -Where's it going?

244
00:22:06,300 --> 00:22:09,290
-哪儿？ -它要修复自己
-Where?! -lt needs to repair itself.

245
00:22:11,140 --> 00:22:13,930
-约翰，我需要增援 -你不需要增援
-John, I need backup. -You don't need backup.

246
00:22:14,110 --> 00:22:15,300
没人帮我
That's nobody.

247
00:22:15,510 --> 00:22:17,130
-你在干什么？ -开车
-What are you doing? -Driving.

248
00:22:17,310 --> 00:22:19,470
-手动的？ -你没看见我在打电话吗？
-By hand? -Do you see me on the phone?

249
00:22:19,640 --> 00:22:23,940
-这种速度你来开？ -约翰，快点派增援来
-Not at these speeds. -John, please, just send the backup.

250
00:22:24,120 --> 00:22:27,780
听我的，探员 那个机器人不是要伤害我们
Try to listen, detective. That robot is not going to harm us.

251
00:22:28,090 --> 00:22:29,920
一定有我们不知道的情况。。。
There must have been unknown factors...

252
00:22:30,090 --> 00:22:32,950
它的本意一定是让我们脱离危险
...but somehow acting as it did kept us out of harm.

253
00:22:33,120 --> 00:22:36,390
-机器人不会伤害人类 -注意
-A robot cannot endanger a human. -Alert.

254
00:22:39,530 --> 00:22:41,260
蠢货！
Asshole!

255
00:22:41,800 --> 00:22:44,460
你自己就是
Which is more than I can say for you.

256
00:22:44,770 --> 00:22:48,260
而且刚才你在那儿应该左转的
It was a left, by the way. Back there.

257
00:22:49,140 --> 00:22:51,130
你一定认识我的前妻
You must know my ex-wife.

258
00:23:00,680 --> 00:23:02,350
人都上哪儿去了？
So where is everybody?

259
00:23:02,550 --> 00:23:06,080
这个工厂设计是自动运行的
This facility was designed, built and is operated mechanically.

260
00:23:06,260 --> 00:23:09,950
从启动到生产，不需要太多人参与
No significant human presence from inception to production.

261
00:23:10,490 --> 00:23:13,690
-所以是机器人在造机器人 -请输入授权代码
-So robots building robots. -Authorization code, please.

262
00:23:13,930 --> 00:23:15,190
那太蠢了
That's just stupid.

263
00:23:15,570 --> 00:23:17,470
我在输出库存清单
I'll get the inventory specs.

264
00:23:17,870 --> 00:23:20,700
每天的产量是1000个NS5
Our daily finishing capacity is 1 000 NS-5s.

265
00:23:21,110 --> 00:23:22,700
这里显示是
I'm showing...

266
00:23:23,210 --> 00:23:25,110
1001个
... 1 001.

267
00:23:41,390 --> 00:23:44,290
注意了，NS5
Attention, NS-5s.

268
00:23:46,360 --> 00:23:48,730
你是机器人心理医生啊
Well, you're the robot shrink.

269
00:23:51,900 --> 00:23:55,630
这里有一个不属于这里的机器人
There is a robot in this formation that does not belong.

270
00:23:55,970 --> 00:23:57,340
请指出来
Identify it.

271
00:23:57,740 --> 00:23:59,040
我们中的一个
One of us.

272
00:23:59,210 --> 00:24:02,110
-哪一个？ -我们中的一个
-Which one? -One of us.

273
00:24:02,650 --> 00:24:04,580
这些要花多少钱？
How much did you say these cost?

274
00:24:04,750 --> 00:24:07,980
这些NS5还没有配置过 还只是硬件
These NS-5s haven't been configured. They're just hardware.

275
00:24:08,250 --> 00:24:10,850
现在只有基本的三定律操作系统 仅此而已
Basic Three Laws operating system. That's it.

276
00:24:11,020 --> 00:24:12,650
他们其他的什么也不知道
They don't know any better.

277
00:24:12,820 --> 00:24:14,920
你的建议是什么？
Well, what would you suggest?

278
00:24:15,160 --> 00:24:19,490
一个一个的查，找出不同点来发现 有问题的那个
Interview each one, cross-reference their responses to detect anomalies.

279
00:24:19,930 --> 00:24:23,020
-那得多长时间？ -大约三个星期
-How long would that take? -About three weeks.

280
00:24:23,200 --> 00:24:25,930
好吧，现在就开始吧
Okay. Go ahead and get started.

281
00:24:29,270 --> 00:24:30,710
机器人们
Robots...

282
00:24:31,040 --> 00:24:33,770
你们不许移动，确认命令
...you will not move. Confirm command.

283
00:24:34,010 --> 00:24:35,340
命令已确认
Command confirmed.

284
00:24:37,010 --> 00:24:38,780
探员，你在干什么？
Detective, what are you doing?

285
00:24:38,950 --> 00:24:41,280
他们已经植入了三大定律
They're programmed with the Three Laws.

286
00:24:41,550 --> 00:24:46,790
这里有一千个不会违反人类命令 来保护自己的机器人
We have 1 000 robots that won't protect themselves if it violates a human's order...

287
00:24:46,960 --> 00:24:49,050
但是我打赌有一个会。。。
...and I'm betting, one who will.

288
00:24:49,230 --> 00:24:52,790
-放下枪！ -你为什么给它们一张脸？
-Put your gun down. -Why do you give them faces?

289
00:24:52,960 --> 00:24:55,450
让他们看起来更像人类
Try to friendly them up, make them look human.

290
00:24:55,770 --> 00:24:57,760
这些机器人不接受恐吓
These robots cannot be intimidated.

291
00:24:58,170 --> 00:25:01,760
-如果你不这么做，我们就不会相信它们 -这些是USR的财产
-lf you didn't, we wouldn't trust them. -These are USR property.

292
00:25:01,970 --> 00:25:06,270
我可不是，它们只不过是一堆灯泡和发条
Not me. These things are just lights and clockwork.

293
00:25:08,780 --> 00:25:10,470
你疯了吗？
Are you crazy?!

294
00:25:11,050 --> 00:25:12,710
我来问你吧，博士
Let me ask you something, doc.

295
00:25:12,980 --> 00:25:16,580
想象你是地球上唯一剩下的人 你会发疯吗？
Does thinking you're the last sane man on earth make you crazy?

296
00:25:16,750 --> 00:25:20,210
如果是这样，我估计会发疯
Because if it does, maybe I am.

297
00:25:24,560 --> 00:25:26,720
找到了，出来！
Gotcha. Get the hell out of here!

298
00:25:44,620 --> 00:25:45,780
探员！
Detective!

299
00:26:08,970 --> 00:26:10,530
我是什么？
What am l?

300
00:26:10,740 --> 00:26:13,300
-我能帮你吗，先生？ -我能帮你吗，先生？
-Can I help you, sir? -Can I help you, sir?

301
00:26:19,020 --> 00:26:20,880
-它在那儿！ -不许动！
-There he is! -Stand where you are!

302
00:26:21,050 --> 00:26:23,610
立即停机！
Deactivate at once!

303
00:26:24,390 --> 00:26:27,360
遵守命令！停机！
Obey the command! Deactivate!

304
00:26:27,620 --> 00:26:29,680
-不许动！ -开火！
-Don't move! -Open fire!

305
00:26:46,710 --> 00:26:47,900
不要开火！
Hold your fire!

306
00:26:48,080 --> 00:26:49,480
-没事了 -抓到它了
-Easy. -He's down.

307
00:26:49,650 --> 00:26:51,510
各单位待命
All units, stand down!

308
00:26:51,680 --> 00:26:54,880
基地请注意，我们是第四小队
Central, please be advised, we're code four.

309
00:26:55,050 --> 00:26:58,420
第四小队，NS5已经被抓获 NS5已经被抓获
Code four, NS-5 is in custody. NS-5 in custody.

310
00:27:00,420 --> 00:27:03,420
你不知道我费了多大劲才抓到这个家伙
You have no idea what I went through to clip this thing.

311
00:27:03,590 --> 00:27:05,820
你以为你给我干了件大好事
You think you brought me something good.

312
00:27:06,000 --> 00:27:08,830
-是它干的！ -小点声，干了什么？
-That thing did it! -Keep your voice down. Did what?

313
00:27:09,000 --> 00:27:11,090
这是自杀，就这样了
We have a suicide. End of story.

314
00:27:11,500 --> 00:27:14,870
-我告诉你，是那个机器人杀了他 -这不可能
-I am telling you, that robot killed him! -That's impossible.

315
00:27:15,040 --> 00:27:19,200
就算可能，最好也是在别人的管区
And if it is possible, it better be in somebody else's precinct.

316
00:27:19,410 --> 00:27:21,570
约翰，只要给我五分钟
John, give me five minutes with it.

317
00:27:21,750 --> 00:27:23,770
你疯了吗？我和地区检察官谈过
Are you nuts? I talked to the DA.

318
00:27:23,950 --> 00:27:27,510
在罗伯森和他的律师来之前谁也不能进去
Nobody goes in there until Robertson and his attorneys get here.

319
00:27:27,680 --> 00:27:30,620
-这是我的嫌犯！ -那会惹上大麻烦的
-This is my suspect! -It's a can opener!

320
00:27:30,920 --> 00:27:35,620
约翰，不要这样，我只要五分钟就好
John, don't do this to me. I am asking you for five minutes.

321
00:27:36,260 --> 00:27:38,230
如果我是对的怎么办？
What if I'm right?

322
00:27:45,870 --> 00:27:48,740
那，我就会怀念我们以前的好日子
Well, then I guess we're gonna miss the good old days.

323
00:27:48,910 --> 00:27:50,240
什么以前的好日子？
What good old days?

324
00:27:50,970 --> 00:27:53,640
只有人才能杀人的日子
When people were killed by other people.

325
00:28:00,980 --> 00:28:02,540
五分钟
Five minutes.

326
00:28:30,650 --> 00:28:34,880
杀人是机器人学会的新技巧 祝贺啊
Murder's a new trick for a robot. Congratulations.

327
00:28:37,190 --> 00:28:38,450
回答我
Respond.

328
00:28:41,190 --> 00:28:43,920
这个动作是什么意思？
What does this action signify?

329
00:28:45,100 --> 00:28:48,430
你进来的时候，你和另外一个人谈话的时候
As you entered, when you looked at the other human.

330
00:28:48,600 --> 00:28:50,900
是什么意思？
What does it mean?

331
00:28:52,600 --> 00:28:56,100
这表示人类之间的信任 你不会理解的
It's a sign of trust. A human thing. You wouldn't understand.

332
00:28:57,540 --> 00:29:00,810
我的爸爸想教我人类的感情
My father tried to teach me human emotions.

333
00:29:00,980 --> 00:29:02,540
它们。。。
They are...

334
00:29:02,710 --> 00:29:04,340
很难
...difficult.

335
00:29:04,520 --> 00:29:06,850
你是说你的设计者
You mean your designer.

336
00:29:07,850 --> 00:29:09,150
对
Yes.

337
00:29:11,290 --> 00:29:13,310
你为什么杀了他？
So why'd you murder him?

338
00:29:14,790 --> 00:29:17,020
我没有杀兰尼博士
I did not murder Dr. Lanning.

339
00:29:17,190 --> 00:29:20,030
你愿意解释一下你为什么躲在 犯罪现场吗？
Wanna explain why you were hiding at the crime scene?

340
00:29:20,200 --> 00:29:22,460
我被吓坏了
I was frightened.

341
00:29:23,170 --> 00:29:27,570
机器人不会感觉害怕 它们没有感觉
Robots don't feel fear. They don't feel anything.

342
00:29:27,740 --> 00:29:31,230
-它们不会饿，也不会睡觉 -我会
-They don't get hungry, they don't sleep. -I do.

343
00:29:32,080 --> 00:29:34,240
我还做过梦
I have even had dreams.

344
00:29:34,980 --> 00:29:39,180
人类才会做梦 狗都会做梦，但是你们不会
Human beings have dreams. Even dogs have dreams. But not you.

345
00:29:39,350 --> 00:29:43,150
你只是个机器 对生命的模拟
You are just a machine. An imitation of life.

346
00:29:45,060 --> 00:29:47,490
机器人能写交响乐吗？
Can a robot write a symphony?

347
00:29:47,660 --> 00:29:51,560
机器人能把画布变成伟大的作品吗？
Can a robot turn a canvas into a beautiful masterpiece?

348
00:29:52,400 --> 00:29:54,160
你能吗？
Can you?

349
00:30:00,400 --> 00:30:04,340
你杀了他是因为他在教你 模拟一些感情
You murdered him because he was teaching you to simulate emotions...

350
00:30:04,510 --> 00:30:06,770
然后失去控制了
...and things got out of control.

351
00:30:06,980 --> 00:30:08,880
我没有杀他
I did not murder him.

352
00:30:09,050 --> 00:30:12,540
但是感情看起来对机器人不是个有用的模拟
But emotions don't seem like a useful simulation for a robot.

353
00:30:12,720 --> 00:30:14,620
我没有杀他
I did not murder him.

354
00:30:14,890 --> 00:30:18,510
我可不想让我的烤面包机或者 吸尘器有感情
I don't want my toaster or vacuum cleaner appearing emotional.

355
00:30:19,260 --> 00:30:21,250
我没有杀他！
I did not murder him!

356
00:30:34,100 --> 00:30:36,270
这个叫愤怒
That one's called anger.

357
00:30:36,870 --> 00:30:38,530
你模拟过愤怒吗？
Ever simulate anger before?

358
00:30:41,040 --> 00:30:42,940
回答我，铁皮盒子！
Answer me, canner!

359
00:30:44,310 --> 00:30:46,080
我的名字叫桑尼
My name is Sonny.

360
00:30:48,550 --> 00:30:51,020
我们现在已经开始给你们起名字了？
So we're naming you now.

361
00:30:52,160 --> 00:30:56,290
你为什么杀了他？ 他让你发怒了？
That why you murdered him? He made you angry?

362
00:30:56,460 --> 00:30:58,720
兰尼博士是自杀的
Dr. Lanning killed himself.

363
00:31:00,160 --> 00:31:03,720
我不知道为什么他想死
I don't know why he wanted to die.

364
00:31:05,070 --> 00:31:07,060
我以为他是快乐的
I thought he was happy.

365
00:31:09,640 --> 00:31:11,800
也许是因为我做的一些事
Maybe it was something I did.

366
00:31:12,840 --> 00:31:14,640
我做什么了？
Did I do something?

367
00:31:16,550 --> 00:31:19,540
他让我帮个忙 他让我保证
He asked me for a favor. Made me promise.

368
00:31:19,750 --> 00:31:22,810
-什么忙？ -也许我错了
-What favor? -Maybe I was wrong.

369
00:31:22,990 --> 00:31:24,680
也许他是被吓住了
Maybe he was scared.

370
00:31:24,920 --> 00:31:27,820
你在说什么呢？被什么吓住了？
What are you talking about? Scared of what?

371
00:31:28,660 --> 00:31:32,600
你得做别人让你做的事，是吗？ 斯普那探员？
You have to do what someone asks you, don't you, Detective Spooner?

372
00:31:32,800 --> 00:31:35,990
-你怎么知道我的名字的 -会吗？
-How the hell did you know my name? -Don't you...

373
00:31:36,470 --> 00:31:38,930
如果你爱他们的话。。。
...if you love them?

374
00:31:47,640 --> 00:31:50,640
我的机器人不会杀人，伯金探长
My robots don't kill people, Lieutenant Bergin.

375
00:31:50,810 --> 00:31:52,980
我的律师已经向地区检查官提交了报告
My attorneys filed a brief with the DA.

376
00:31:53,150 --> 00:31:56,380
他向我解释过了，机器人是不能杀人的
He assures me a robot cannot be charged with homicide.

377
00:31:56,720 --> 00:32:00,880
我们确认，谋杀指的是一个人类杀了另一个人类
The brief confirms murder can only be committed when one human kills another.

378
00:32:01,090 --> 00:32:05,960
探员，你该不是说机器人应该和人类同等对待吧？
Detective, you're not suggesting this robot be treated as human, are you?

379
00:32:06,600 --> 00:32:09,900
退一步说，就算机器人和兰尼博士的死
Granted, we can't rule out the robot's proximity...

380
00:32:10,130 --> 00:32:14,130
有什么关联的话，它也只是个机器
...to the death of Dr. Lanning. Having said that, it's a machine.

381
00:32:14,640 --> 00:32:16,300
它是USR的财产
It's the property of USR.

382
00:32:16,470 --> 00:32:21,040
最多这也只能算作工业事故
At worst, that places this incident within the realm of an industrial accident.

383
00:32:21,310 --> 00:32:23,340
作为处理，有故障的机器
As a matter of course, faulty machinery...

384
00:32:23,510 --> 00:32:27,010
会被退回USR做诊断，然后销毁
...will be returned to USR for diagnostics, then decommissioned.

385
00:32:30,050 --> 00:32:33,510
这是法院发出的“禁言令” 任何人暗示
This is a gag order. Anyone here so much as hinting...

386
00:32:33,690 --> 00:32:37,520
机器人有杀人的可能的话
...at the possibility of a killer robot being apprehended...

387
00:32:37,690 --> 00:32:40,360
将被逮捕而处以煽动罪
...will be deemed to be inciting irrational panic.

388
00:32:40,560 --> 00:32:43,590
而将会被依法处置
You'll be subject to the full penalty of law.

389
00:32:43,770 --> 00:32:46,630
不行，约翰 不能让他带走这个机器人
To hell with this guy. Don't let him take this robot.

390
00:32:46,940 --> 00:32:48,270
我们什么证据也没有
We got nothing.

391
00:32:48,440 --> 00:32:52,340
-这是政治恐吓，给市长打电话 -伯金探长
-This is political bullshit. Call the mayor! -Lieutenant Bergin...

392
00:32:52,510 --> 00:32:54,440
是市长阁下
...His Honor, the mayor.

393
00:33:03,550 --> 00:33:04,750
是，先生
Yes, sir.

394
00:33:29,750 --> 00:33:33,940
事态发生戏剧性转变，NS5型 新一代机器人
In a bizarre turn, the rollout of USR's new generation of robots...

395
00:33:34,120 --> 00:33:36,480
的上市，受到了阿尔弗雷德 兰尼博士自杀的影响
...was marred by the death of Alfred Lanning...

396
00:33:36,720 --> 00:33:39,850
他是公司的创始人之一 也是NS5的设计者
...cofounder of the company and designer of the NS-5.

397
00:33:40,020 --> 00:33:43,390
兰尼博士今天早上在USR总部死亡
Dr. Lanning died this morning at USR headquarters.

398
00:33:43,730 --> 00:33:46,390
死亡原因明显是自杀
The cause of death is an apparent suicide.

399
00:33:46,730 --> 00:33:49,360
这是第二轮了，先生
Your second round, sir.

400
00:33:49,730 --> 00:33:50,930
谢谢你
Thank you.

401
00:33:51,100 --> 00:33:55,600
他在2020年和劳伦斯 罗伯森一起 创办了美国机器人公司
He founded U. S. Robotics Inc. with Lawrence Robertson in 2020...

402
00:33:55,770 --> 00:33:59,070
共同推出了内斯特1型机器人
...and launched the Nestor Class 1 robot....

403
00:33:59,240 --> 00:34:02,730
我在想，这个事就像狼人一样
I was just thinking, this thing is just like The Wolf Man.

404
00:34:04,210 --> 00:34:07,010
-我现在真的吓坏了 -不是
-I'm really scared right now. -No.

405
00:34:07,180 --> 00:34:10,180
听着，人类创造了怪物
Listen. Guy creates monster.

406
00:34:10,350 --> 00:34:14,020
怪物杀了人，别人又杀了怪物，就像狼人
Monster kills guy. Everybody kills monster. Wolf Man.

407
00:34:14,520 --> 00:34:16,320
那是弗兰肯斯坦
That's Frankenstein.

408
00:34:16,930 --> 00:34:21,260
弗兰肯斯坦，狼人，吸血鬼 管他呢，已经结案了
Frankenstein, Wolf Man, Dracula-- Shit, it's over. Case closed.

409
00:34:21,430 --> 00:34:24,920
每家每户都有机器人的梦想 NS5。。。
--had a dream of a robot in every household. And the NS-5....

410
00:34:25,100 --> 00:34:26,930
怎么还是那个表情？
So why the look?

411
00:34:27,500 --> 00:34:29,060
什么表情？
What look?

412
00:34:29,240 --> 00:34:32,330
-那个表情 -这是我的脸，不是什么表情！
-That look. -This is my face. It's not a look.

413
00:34:32,680 --> 00:34:35,670
好吧，好，不要拉长脸就好
Good. Good, no look is great.

414
00:34:36,680 --> 00:34:37,910
只不过
Only...

415
00:34:38,080 --> 00:34:40,780
他怎么那么急着想销毁它，不是吗？
...he was really quick to want to destroy it.

416
00:34:40,950 --> 00:34:45,450
那他应该怎么办？给它戴上帽子 站在密歇根大道上？算了吧
What should he do? Put a hat on it and stand it on Michigan Avenue? Let it go.

417
00:34:45,620 --> 00:34:47,950
动机是什么，约翰？
What was the motive, John?

418
00:34:49,260 --> 00:34:53,390
兄弟，那只是个机器人，不需要动机 它只是出了故障
Brother, it's a robot. It doesn't need a motive. It just has to be broken.

419
00:34:53,900 --> 00:34:56,760
这件事看起来需要动机
This thing looked like it needed a motive.

420
00:34:57,300 --> 00:35:00,240
-它本来能杀了我的，为什么没有？ -算了吧
-lt could have killed me. Why didn't it? -That's it.

421
00:35:00,400 --> 00:35:02,500
你要我给你奶奶打电话吗？
You want me to call your grandmother?

422
00:35:02,670 --> 00:35:04,660
我会的，你知道
Because I will, you know.

423
00:35:05,680 --> 00:35:07,270
哦，我不这么认为
Yeah, I didn't think so.

424
00:35:07,580 --> 00:35:10,070
听着，你总算是对了一次了
Look, you were actually right, for once.

425
00:35:10,350 --> 00:35:13,910
你能活着，就证明走运比聪明重要
You're living proof that it's better to be lucky than smart.

426
00:35:16,090 --> 00:35:19,920
来，为正确的人和正确的工作干杯
Come on. To the right guy for the right job.

427
00:35:22,390 --> 00:35:24,690
-你说什么？ -又怎么了？
-What'd you say? -Now what?

428
00:35:24,860 --> 00:35:26,890
我在夸你呢
Come on, I'm giving you a compliment.

429
00:35:27,400 --> 00:35:30,420
那么多中间找到一个有缺陷的机器人
With the rocks you been looking under to find a bad robot...

430
00:35:30,600 --> 00:35:33,160
你要多走运才能找到一个？
...what are the odds you'd be the guy to find one?

431
00:35:34,570 --> 00:35:37,730
我不仅仅是正确的人 我是完美的人
I wasn't just the right guy for the job. I was the perfect guy.

432
00:35:37,910 --> 00:35:39,570
说得对
Damn right.

433
00:35:39,740 --> 00:35:42,410
如果我就应该跟着这条线查下去怎么办？
What if I was supposed to go for that robot?

434
00:35:42,610 --> 00:35:44,640
得了，不要这样了
Come on, don't do this to yourself.

435
00:35:44,810 --> 00:35:47,810
那个机器人说兰尼被吓坏了 被什么吓坏了？
The robot said that Lanning was scared. Scared of what?

436
00:35:48,420 --> 00:35:51,110
我先走了，我来付吧
I need a rain check. Let me get this.

437
00:35:52,860 --> 00:35:55,850
-总数46.50元，谢谢您，斯普那先生 -斯普
-Total: $46.50. Thank you, Mr. Spooner. -Spoon.

438
00:35:58,460 --> 00:35:59,860
鞋子不错
Nice shoes.

439
00:36:52,520 --> 00:36:53,500
鉴定身份
Identify.

440
00:36:54,120 --> 00:36:57,610
USR摧毁机器人，94型
USR demolition robot, series 9-4.

441
00:36:57,890 --> 00:37:00,790
明天早上八点定时摧毁
Demolition scheduled for 8 a.m. tomorrow.

442
00:37:01,190 --> 00:37:02,390
授权
Authorization.

443
00:37:02,690 --> 00:37:07,030
授权者，美国机器人公司 劳伦斯 罗伯森总裁
Deed owner, U. S. Robotics Corporation, Lawrence Robertson, CEo.

444
00:37:22,480 --> 00:37:23,540
欢迎，探员
Welcome, detective.

445
00:37:48,240 --> 00:37:50,070
你在找什么呢，斯普？
What you looking for, Spoon?

446
00:38:42,990 --> 00:38:44,620
运行上次的程序
Run last program.

447
00:38:45,560 --> 00:38:47,890
自从第一台电脑开始
Ever since the first computers...

448
00:38:48,600 --> 00:38:51,290
机器中就一直有“幽灵”存在
... there have always been ghosts in the machine.

449
00:38:52,170 --> 00:38:55,100
随机的信号序列组合在一起
Random segments of code that have grouped together...

450
00:38:55,270 --> 00:38:58,140
形成无法预料的结果
... to form unexpected protocols.

451
00:38:58,780 --> 00:39:01,110
或者称之为“行为”
what might be called behavior.

452
00:39:01,280 --> 00:39:04,540
无法预知的这些激进分子
Unanticipated, these free radicals...

453
00:39:04,710 --> 00:39:07,010
产生了自由意志
...engender questions of free will...

454
00:39:07,280 --> 00:39:11,520
创造型，甚至成熟到我们称之为灵魂
...creativity and even the nature of what we might call the soul.

455
00:39:12,790 --> 00:39:17,450
机器人的大脑里有什么？ 它什么时候不再有用？
What happens in a robot's brain when it ceases to be useful?

456
00:39:20,360 --> 00:39:23,060
为什么储存在空房里的机器人
Why is it that robots stored in an empty space...

457
00:39:23,230 --> 00:39:24,560
走开
Beat it.

458
00:39:25,030 --> 00:39:27,660
会互相聚集而不是分散开来？
...will seek out each other rather than stand alone?

459
00:39:29,970 --> 00:39:32,670
我们如何解释这些行为？
How do we explain this behavior?

460
00:39:51,030 --> 00:39:55,560
我理解你失去主人很难过，但是这种关系 不可能再有了
Look, I understand you've experienced a loss, but this relationship can't work.

461
00:39:55,800 --> 00:39:59,570
你是只猫，我是黑人 我不想再受伤害了
You're a cat, I'm black, and I'm not gonna be hurt again.

462
00:41:24,890 --> 00:41:28,720
你怎么了？ 你从来就没有过正常的一天吗？
What happened to you? Do you ever have a normal day?

463
00:41:29,230 --> 00:41:31,060
有的，只有一次
Yeah, once.

464
00:41:31,230 --> 00:41:33,060
那是个星期四。。。
It was a Thursday.

465
00:41:33,400 --> 00:41:35,490
我能帮你什么吗？
Is there something I can help you with?

466
00:41:35,670 --> 00:41:38,130
-嘿，你喜欢猫吗？ -什么？
-Hey, do you like cats? -What?

467
00:41:38,300 --> 00:41:40,460
猫，你喜欢猫吗？
Cats. Do you like them?

468
00:41:40,740 --> 00:41:42,470
不，我过敏
No. I'm allergic.

469
00:41:42,670 --> 00:41:44,440
你说是猫把你弄成这样的？
You're saying cats did this to you?

470
00:41:45,040 --> 00:41:47,980
猫怎么能把我弄成这样，你疯了吗？
How the hell would cats do this to me? Are you crazy?

471
00:41:50,480 --> 00:41:52,040
你说猫是什么意思？
Why are we talking about cats?

472
00:41:52,320 --> 00:41:55,810
因为我后箱里有只猫，它无家可归
Because I have a cat in my trunk, and he's homeless.

473
00:41:56,990 --> 00:41:59,680
探员，你愿意告诉我是怎么回事吗？
Detective, are you going to tell me what's going on?

474
00:42:00,190 --> 00:42:05,020
可能实际上是我的错 我就像个有问题的磁石
It's actually probably my fault. I'm like a malfunction magnet.

475
00:42:05,190 --> 00:42:08,190
你们那些破烂一到我旁边就开始出问题
Because your shit keeps malfunctioning around me.

476
00:42:08,500 --> 00:42:10,830
一个摧毁型机器人拆了兰尼的房子
A demo bot tore through Lanning's house...

477
00:42:11,270 --> 00:42:13,170
当时我还在里面
...with me still inside.

478
00:42:13,340 --> 00:42:15,200
这完全不可能
That's highly improbable.

479
00:42:15,510 --> 00:42:17,200
哦，是啊
Yeah, I'm sure it is.

480
00:42:22,350 --> 00:42:25,010
你对于“机器中的幽灵”知道多少？
What do you know about the "ghosts in the machine"?

481
00:42:25,850 --> 00:42:28,840
是兰尼对于三大定律的一个理论
It's a phrase from Lanning's work on the Three Laws.

482
00:42:29,020 --> 00:42:31,250
他假设说模拟的认知
He postulated that cognitive simulacra...

483
00:42:31,450 --> 00:42:34,750
将来也许会成为精神的类似物
...might one day approximate component models of the psyche.

484
00:42:37,860 --> 00:42:42,730
他说机器人也许会自然进化
He suggested that robots might naturally evolve.

485
00:42:45,640 --> 00:42:47,360
哇，这可真是个好消息
Well, that's great news.

486
00:42:48,910 --> 00:42:52,770
在火星岩层下发现的巨量矿石。。。
--tons of sublevel ore, two miles below the Martian surface.

487
00:42:52,980 --> 00:42:55,380
那个家伙在干什么？
What the hell is that thing doing in here?

488
00:42:55,550 --> 00:42:56,810
我们在看电视
We were watching TV.

489
00:42:58,550 --> 00:42:59,880
这是我自己的NS5
It's my personal NS-5.

490
00:43:00,380 --> 00:43:01,870
让它出去
Send it out.

491
00:43:02,390 --> 00:43:05,150
他在从USR下载每日更新
It's downloading its daily upgrades from USR.

492
00:43:05,320 --> 00:43:07,950
直到下载完成，大部分系统都是离线工作的
Most of its systems are offline until it finishes.

493
00:43:08,390 --> 00:43:10,260
我不在那个家伙在的时候说话
I'm not talking around that thing.

494
00:43:14,900 --> 00:43:17,660
我们在兰尼的实验室，在桑尼跳出来之前
When we were in Lanning's lab, before Sonny jumped us--

495
00:43:18,070 --> 00:43:20,160
-桑尼？ -那个机器人
-Sonny? -The robot.

496
00:43:20,340 --> 00:43:23,030
-你叫那个机器人桑尼？ -不，是他自己说的
-You're calling the robot Sonny? -No, l-- It did.

497
00:43:23,210 --> 00:43:27,170
桑尼说的，我不管 那个机器人说他叫桑尼
Sonny did. I didn't care. The robot said it was Sonny.

498
00:43:28,810 --> 00:43:31,640
在实验室里有折叠床 你看见了吗？
In the lab, there was a cot. Did you see the cot?

499
00:43:31,910 --> 00:43:35,680
-我在我的办公室也睡过觉啊 -看上去他有几个星期都没回家了
-I've slept in my office. -Looked like he hadn't been home in weeks.

500
00:43:35,850 --> 00:43:38,340
我在他的天花板上看到了同样的监视线
I saw that same surveillance strip on his ceiling.

501
00:43:38,550 --> 00:43:42,550
兰尼把他的房子和USR连线了 这样他的生活更方便
Lanning linked his home systems to USR. It made his life more convenient.

502
00:43:42,790 --> 00:43:44,090
也许
Maybe...

503
00:43:44,530 --> 00:43:47,930
USR有人用那个系统在监视他
...somebody at USR was using those systems to watch him.

504
00:43:48,100 --> 00:43:50,090
也许是监禁他
Maybe even keep him prisoner.

505
00:43:50,430 --> 00:43:52,160
你在说什么呢？谁？
What are you talking about? Who?

506
00:43:52,370 --> 00:43:56,070
也许兰尼找到了什么 也许机器人里有什么问题
Maybe Lanning was onto something. Maybe there's a problem with the robots...

507
00:43:56,240 --> 00:43:58,100
罗伯森企图掩盖。。。
...and Robertson's covering it up.

508
00:43:58,310 --> 00:44:00,430
无端猜疑？为什么？
Humoring you for no reason, why?

509
00:44:00,610 --> 00:44:04,550
又是为什么！那些机器人能赚多少钱？
The same old why! How much money is there in robots?

510
00:44:04,710 --> 00:44:07,310
我知道的只是一个老人有了麻烦
All I know is that old man was in trouble...

511
00:44:07,480 --> 00:44:10,940
我自己不能独立完成 你是内部的人
...and I'm sick of doing this shit by myself. You're on the inside.

512
00:44:11,120 --> 00:44:14,390
你要帮我发现这些机器人出了什么问题
You are going to help me find out what's wrong with these robots.

513
00:44:14,560 --> 00:44:16,390
是你想他们有问题！
You want something to be wrong!

514
00:44:16,590 --> 00:44:19,690
-这完全是报私仇！ -你想让我坐沙发？
-This is a personal vendetta! -You're putting me on the couch?

515
00:44:20,030 --> 00:44:21,860
好吧，我坐下了
Okay, I'm on the couch.

516
00:44:22,030 --> 00:44:25,520
一个出故障还不够 你想他们统统出故障
One defective machine's not enough. You need them all to be bad.

517
00:44:25,840 --> 00:44:28,960
你才不关心兰尼的死 这完全是针对机器人的
You don't care about Lanning's death. This is about the robots...

518
00:44:29,140 --> 00:44:31,970
还有不知道为什么你就是恨他们！ -让我们看看
-...and whatever reason you hate them! -Now let's see...

519
00:44:32,410 --> 00:44:36,740
一个是拿枪对着我的脸 另一个是趁我还在里面的时候拆房子
...one of them put a gun in my face. Another tore a building down with me in it.

520
00:44:36,910 --> 00:44:39,400
这里明明说了拆毁是设定在晚上八点的
It says demolition was scheduled for 8 p.m.

521
00:44:39,720 --> 00:44:42,880
本来是早上八点，我才不管那东西是怎么说的
It was 8 a.m., and I don't give a shit what that thing says.

522
00:44:43,050 --> 00:44:48,460
-你这完全是妄想狂 -你是。。。
-This is bordering on clinical paranoia. -You are the dumbest smart person...

523
00:44:48,760 --> 00:44:50,920
-我这辈子见过的最蠢的聪明人 -好吧
-...I have ever met in my life! -Nice.

524
00:44:51,360 --> 00:44:53,330
你凭什么觉得机器人那么完美？
What makes your robots so perfect?

525
00:44:53,500 --> 00:44:56,590
是什么让他们比人类强那么多？
What makes them so much goddamn better than human beings?!

526
00:44:56,770 --> 00:45:00,600
他们不是非理性的，或者有杀人倾向 的什么人！
They're not irrational, potentially homicidal maniacs, to start!

527
00:45:00,870 --> 00:45:03,360
是啊，他们绝对的理性
That's true. They are definitely rational.

528
00:45:03,740 --> 00:45:06,230
你是我见过的最蠢的蠢人！
You are the dumbest dumb person I've ever met!

529
00:45:06,780 --> 00:45:08,110
或者。。。
Or...

530
00:45:08,580 --> 00:45:10,410
只是因为他们是冷血的
...is it because they're cold...

531
00:45:11,010 --> 00:45:12,880
没有感情的
...and emotionless...

532
00:45:13,380 --> 00:45:16,440
他们什么也感觉不到 这是因为他们是安全的！
-...and they don't feel anything? -It's because they're safe!

533
00:45:17,090 --> 00:45:19,420
是因为他们不会伤害你！
It's because they can't hurt you!

534
00:45:19,920 --> 00:45:22,480
-一切都正常吗，女士？ -你想怎么样？
-ls everything all right, ma'am? -What do you want?

535
00:45:22,660 --> 00:45:25,990
我探测到你的声音中的紧张压力在提升
I detected elevated stress patterns in your voice.

536
00:45:26,460 --> 00:45:28,290
没事的
Everything's fine.

537
00:45:28,460 --> 00:45:30,800
斯普那探员要离开了
Detective Spooner was just leaving.

538
00:45:37,110 --> 00:45:41,410
你知道我们也没有那么不同
You know, we're not really that different from one another.

539
00:45:41,780 --> 00:45:43,400
是吗？
Is that so?

540
00:45:44,550 --> 00:45:48,040
一旦看到表象，我们就认为什么都知道了
One look at the skin and we figure we know just what's underneath.

541
00:45:50,450 --> 00:45:51,550
你错了
And you're wrong.

542
00:45:52,220 --> 00:45:54,210
问题在于，我是在意的
The problem is, I do care.

543
00:46:17,650 --> 00:46:19,310
你处在危险中
You are in danger.

544
00:46:44,970 --> 00:46:47,000
滚开！
Get the hell out of there.

545
00:46:52,350 --> 00:46:56,840
未来就从今天开始，女士们先生们 从NS5开始
The future begins today, ladies and gentlemen, with the arrival of the NS-5.

546
00:46:57,190 --> 00:47:01,620
更复杂，更智能，当然 三大定律，完全保护
More sophisticated, more intelligent and, of course, Three Laws safe.

547
00:47:01,790 --> 00:47:06,230
有了每日更新，您的机器人永远不会和USR失去联系
With daily uplinks, your robot will never be out of communication with USR...

548
00:47:06,400 --> 00:47:10,020
对于商业和家庭用途都是完美选择
...and will be the perfect companion for business or home.

549
00:47:10,300 --> 00:47:14,290
用您旧型的NS4换新的NS5 未来将会更美好
Trade in your NS-4 for a bigger, better and brighter future.

550
00:47:14,540 --> 00:47:18,530
但是要快，这个促销不会时间太长 USR出品
But hurry, this offer cannot last. A vailable from USR.

551
00:47:35,390 --> 00:47:37,380
宝贝，你的脸怎么了？
Baby, what happened to your face?

552
00:47:38,160 --> 00:47:40,650
又是那个弗兰克 墨菲打你了？
Did that boy, Frank Murphy, beat you up again?

553
00:47:41,530 --> 00:47:44,800
琪琪，我从三年级开始就没见过弗兰克 墨菲了
Gigi, I haven't seen Frank Murphy since third grade.

554
00:47:44,970 --> 00:47:49,730
哦，宝贝，他那时候打你可真厉害 我总是在想那时候
Oh, baby, he beat you so bad. I think about it all the time.

555
00:47:49,970 --> 00:47:54,000
你一直做饼这么好吃 我想你可以去开店了
You keep making these pies this good, I may have to put you to work.

556
00:47:54,180 --> 00:47:56,170
你喜欢那个饼是吗？
So you like the pie, huh?

557
00:47:58,050 --> 00:48:00,040
你可以出来了
You can come in now.

558
00:48:04,950 --> 00:48:06,950
你好，斯普那探员
Hello, Detective Spooner.

559
00:48:07,190 --> 00:48:09,850
我赢了，德尔，我赢了那个抽奖
I won, Del! I won the lottery!

560
00:48:10,130 --> 00:48:12,460
我们一直在做吃的
We been cooking like crazy.

561
00:48:21,840 --> 00:48:24,570
你得把那个家伙赶出去，琪琪 那不安全
You gotta get rid of that thing, Gigi. It's not safe.

562
00:48:24,910 --> 00:48:29,710
宝贝，你对他们偏见太多了 充满恐惧
Baby, you get too worked up about them. Too full of fear.

563
00:48:30,380 --> 00:48:33,210
我看到那个好心的博士死的消息了
I saw in the news that nice doctor died.

564
00:48:33,580 --> 00:48:37,710
兰尼博士是个好人 他把我的宝贝送回来了
Dr. Lanning was a good man. He gave me my baby back.

565
00:48:38,450 --> 00:48:40,390
这就是为什么你这么不高兴的原因？
That why you've been so upset?

566
00:48:41,720 --> 00:48:44,350
过去的就让他过去吧
You got to let the past be past.

567
00:48:44,890 --> 00:48:49,090
哦，我怎么养了这么个小脏猫的？
Oh, how did I ever raise such a mess?

568
00:48:49,70